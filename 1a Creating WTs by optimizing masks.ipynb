{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d3d387b",
   "metadata": {},
   "source": [
    "# Optimizing Masks to create WTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fed2c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 19:37:43.732734: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# importing necessary libraries and the cnn architecture I defined\n",
    "\n",
    "from cnn_architecture import CNN2Model\n",
    "from utils import *\n",
    "from load_datasets import load_and_prep_dataset\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "#import tensorflow_probability as tfp\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.io import loadmat\n",
    "import copy\n",
    "\n",
    "# all the extra stuff for supermasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08c7e8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f279914f",
   "metadata": {},
   "source": [
    "all the variables i have to check their meaning:\n",
    "- use bias\n",
    "- dynamik scaling\n",
    "- sigmoid bias\n",
    "- use learning phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd6c229d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedDense(tf.keras.Layer):\n",
    "    def __init__(self, units=32, activation = tf.keras.activations.relu):\n",
    "        super().__init__()\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "\n",
    "    # Create the state of the layer (weights)\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"glorot_uniform\",\n",
    "            trainable=False,\n",
    "            name=\"kernel\",\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            shape=(self.units,),\n",
    "            initializer=tf.keras.initializers.Constant(value=0.0000000001),\n",
    "            trainable=False,\n",
    "            name=\"bias\",\n",
    "        )\n",
    "        self.mask = self.add_weight(\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=tf.keras.initializers.RandomUniform(minval=0.0, maxval=1, seed=None),\n",
    "            trainable=True,\n",
    "            name=\"mask\",\n",
    "        )\n",
    "\n",
    "    # Defines the computation\n",
    "    #@tf.function\n",
    "    def call(self, inputs):\n",
    "        masked_weights = tf.math.multiply(self.kernel, self.mask)\n",
    "        net_activation = tf.linalg.matmul(inputs, masked_weights) + self.bias\n",
    "        return self.activation(net_activation)\n",
    "    \n",
    "    def normalize_pruning_rate(self, p_rate):\n",
    "        percentile = np.percentile(self.mask, p_rate)\n",
    "        self.kernel = self.kernel + (0.5-percentile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "517a819b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2ModelMasked(tf.keras.Model):\n",
    "    \n",
    "    # basic\n",
    "    def __init__(self):\n",
    "        super(CNN2ModelMasked, self).__init__()\n",
    "        \n",
    "        # set biases to a value that is not exactly 0.0, so they don't get handled like pruned values\n",
    "        self.bias_in = tf.keras.initializers.Constant(value=0.0000000001)\n",
    "        \n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3,activation=\"relu\", padding=\"same\",kernel_initializer='glorot_uniform', bias_initializer=self.bias_in) # [batchsize,32,32,64]\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3,activation=\"relu\", padding=\"same\",kernel_initializer='glorot_uniform', bias_initializer=self.bias_in) # [batchsize,32,32,64]\n",
    "        self.maxpool = tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2, 2),input_shape=(32, 32, 64)) # [batchsize,16,16,64]\n",
    "        self.flatten = tf.keras.layers.Flatten() # [batch_size,16384]\n",
    "        self.dense1 = MaskedDense(256, activation=tf.keras.activations.relu) # [batch_size,256]\n",
    "        self.dense2 = MaskedDense(256, activation=tf.keras.activations.relu) # [batch_size,256]\n",
    "        self.dense3 = MaskedDense(10, activation=tf.keras.activations.softmax) # [batch_size,256]\n",
    "        \n",
    "        # Making the weights of the conv layers untrainable\n",
    "        self.conv1.trainable = False\n",
    "        self.conv2.trainable = False\n",
    "    \n",
    "    #@tf.function\n",
    "    def call(self, inputs):\n",
    "        \n",
    "        # adjust the dense layers to be multiplayed with trainable mask (which gets assigned binary values for this step)\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42718cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified train loop to also work with sparse networks (such that pruned weights remain frozen at 0.0)\n",
    "\n",
    "def train_mask(train, test, model, num_epochs=5):\n",
    "    \n",
    "    # hyperparameters\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002)\n",
    "    loss_function= tf.keras.losses.CategoricalCrossentropy()\n",
    "    \n",
    "    # initializing training statistics\n",
    "    train_accuracy = tf.keras.metrics.Accuracy(name='test_accuracy')\n",
    "    test_accuracy = tf.keras.metrics.Accuracy(name='train_accuracy')\n",
    "    train_losses = tf.keras.metrics.CategoricalCrossentropy(name='train_losses')\n",
    "    test_losses = tf.keras.metrics.CategoricalCrossentropy(name='test_losses')\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "    train_l =[]\n",
    "    test_l = []\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs), leave=False, desc=\"training epochs\"):\n",
    "        \n",
    "        #train step\n",
    "        for x, t in train:\n",
    "            with tf.GradientTape() as tape:\n",
    "                pred = model(x)\n",
    "                loss = loss_function(t, pred)\n",
    "                train_losses.update_state(t, pred)\n",
    "                train_accuracy.update_state(tf.argmax(t,1), tf.argmax(pred,1))\n",
    "            gradients = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        model.normalize_pruning_rate(p_rate = 90)\n",
    "\n",
    "        # test step\n",
    "        for x, t in test:\n",
    "            pred = model(x)\n",
    "            test_accuracy.update_state(tf.argmax(t,1), tf.argmax(pred,1))\n",
    "            test_losses.update_state(t, pred)\n",
    "        \n",
    "        # updataing training statistics\n",
    "        train_acc.append(train_accuracy.result().numpy())\n",
    "        test_acc.append(test_accuracy.result().numpy())\n",
    "        train_l.append(train_losses.result().numpy())\n",
    "        test_l.append(test_losses.result().numpy())\n",
    "        train_accuracy.reset_state()\n",
    "        test_accuracy.reset_state()\n",
    "        train_losses.reset_state()\n",
    "        test_losses.reset_state()\n",
    "        \n",
    "    # collecting losses in a dictionary\n",
    "    losses = { \"test loss\":test_l , \"training loss\":train_l , \"test accuracy\":test_acc , \"training accuracy\":train_acc}\n",
    "    \n",
    "    return  losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cc4a3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-28 19:37:48.135465: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-28 19:37:48.185341: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-28 19:37:48.185593: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-28 19:37:48.186443: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-28 19:37:48.186639: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-28 19:37:48.186842: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-28 19:37:48.236359: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-28 19:37:48.236583: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-28 19:37:48.236736: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-28 19:37:48.236832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2903 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1050 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "/net/projects/scratch/summer/valid_until_31_January_2025/epetersen/miniconda3/envs/thesis/lib/python3.11/site-packages/keras/src/layers/pooling/base_pooling.py:23: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(name=name, **kwargs)\n",
      "2024-05-28 19:37:50.489320: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "2024-05-28 19:37:50.603079: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_weights: \n",
      "(3, 3, 3, 64)\n",
      "(64,)\n",
      "(3, 3, 64, 64)\n",
      "(64,)\n",
      "(16384, 256)\n",
      "(16384, 256)\n",
      "(256,)\n",
      "(256, 256)\n",
      "(256, 256)\n",
      "(256,)\n",
      "(256, 10)\n",
      "(256, 10)\n",
      "(10,)\n",
      "trainable variables: \n",
      "<KerasVariable shape=(16384, 256), dtype=float32, path=cnn2_model_masked/masked_dense/mask>\n",
      "<KerasVariable shape=(256, 256), dtype=float32, path=cnn2_model_masked/masked_dense_1/mask>\n",
      "<KerasVariable shape=(256, 10), dtype=float32, path=cnn2_model_masked/masked_dense_2/mask>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"cnn2_model_masked\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"cnn2_model_masked\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ ?                      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masked_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaskedDense</span>)      │ ?                      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">8,388,864</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masked_dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaskedDense</span>)    │ ?                      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masked_dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaskedDense</span>)    │ ?                      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ ?                      │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ ?                      │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masked_dense (\u001b[38;5;33mMaskedDense\u001b[0m)      │ ?                      │     \u001b[38;5;34m8,388,864\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masked_dense_1 (\u001b[38;5;33mMaskedDense\u001b[0m)    │ ?                      │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ masked_dense_2 (\u001b[38;5;33mMaskedDense\u001b[0m)    │ ?                      │         \u001b[38;5;34m5,130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,564,042</span> (32.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,564,042\u001b[0m (32.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,262,400</span> (16.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,262,400\u001b[0m (16.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,301,642</span> (16.41 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,301,642\u001b[0m (16.41 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training epochs:   0%|          | 0/5 [00:00<?, ?it/s]2024-05-28 19:38:13.184224: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "                                                      \r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CNN2ModelMasked' object has no attribute 'normalize_pruning_rate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(matrix)\n\u001b[1;32m     12\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[0;32m---> 14\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m plot_losses(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTestSuperMaskOptimization\u001b[39m\u001b[38;5;124m\"\u001b[39m, losses,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCNN Loss and Accuracy for supermask model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[5], line 31\u001b[0m, in \u001b[0;36mtrain_mask\u001b[0;34m(train, test, model, num_epochs)\u001b[0m\n\u001b[1;32m     28\u001b[0m     gradients \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, model\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m     29\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(gradients, model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n\u001b[0;32m---> 31\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize_pruning_rate\u001b[49m(p_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m90\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# test step\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, t \u001b[38;5;129;01min\u001b[39;00m test:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CNN2ModelMasked' object has no attribute 'normalize_pruning_rate'"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = load_and_prep_dataset(\"CIFAR\", batch_size=60, shuffle_size=512)\n",
    "\n",
    "model = CNN2ModelMasked()\n",
    "model(list(train_dataset)[0][0])\n",
    "initial_weights = model.get_weights()\n",
    "print(\"initial_weights: \")\n",
    "for matrix in initial_weights:\n",
    "    print(matrix.shape)\n",
    "print(\"trainable variables: \")\n",
    "for matrix in model.trainable_variables:\n",
    "    print(matrix)\n",
    "model.summary()\n",
    "\n",
    "losses = train_mask(train_dataset, test_dataset, model)\n",
    "plot_losses(\"CIFAR\", \"TestSuperMaskOptimization\", losses,\"CNN Loss and Accuracy for supermask model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2cf268",
   "metadata": {},
   "source": [
    "debugging to do:\n",
    "- check paper for optimizer\n",
    "- make the call function simpler\n",
    "- research other examples of unusual trainable parameters in models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27f0c07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
